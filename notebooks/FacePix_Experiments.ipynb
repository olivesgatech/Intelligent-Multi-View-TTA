{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32460d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights, EfficientNet_B0_Weights, VGG16_Weights, Inception_V3_Weights, ViT_B_16_Weights\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, auc\n",
    "from get_uncertainties import get_uncertainties\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ae3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d193ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_output(torch.nn.Module):\n",
    "    def __init__(self, num_classes, input_size):\n",
    "        super(Classifier_output, self).__init__()\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(torch.nn.Linear(input_size, 512), \n",
    "                               torch.nn.ReLU(inplace=True), \n",
    "                               torch.nn.Dropout(0.2),\n",
    "                               torch.nn.Linear(512, 128), \n",
    "                               torch.nn.ReLU(inplace=True), \n",
    "                               torch.nn.Dropout(0.2),\n",
    "                               torch.nn.Linear(128, 32), \n",
    "                               torch.nn.ReLU(inplace=True), \n",
    "                               torch.nn.Dropout(0.2),\n",
    "                               torch.nn.Linear(32, num_classes))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7baa1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ResNet50'\n",
    "if model_name == 'ResNet50':\n",
    "    model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "    model.fc = Classifier_output(num_classes=30, input_size=2048)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.fc.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.fc.fc.parameters(), lr=0.001)\n",
    "    \n",
    "elif model_name == 'VGG16':\n",
    "    model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "    model.classifier[6] = Classifier_output(num_classes=30, input_size=4096)\n",
    "    print(model)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.classifier[6].parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.classifier[6].parameters(), lr=0.001)\n",
    "    \n",
    "elif model_name == 'vit_b_16':\n",
    "    model = models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "    model.heads = Classifier_output(num_classes=30, input_size=768)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.heads.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.heads.fc.parameters(), lr=0.001)\n",
    "    \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fa3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacePix_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img = os.listdir(self.root_dir)[idx]\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                os.listdir(self.root_dir)[idx])\n",
    "            \n",
    "        image = cv2.imread(img_name)\n",
    "        match = re.search(r'\\((-?\\d+)\\)', img)\n",
    "        if match:\n",
    "            angle = int(match.group(1))\n",
    "            if angle <= 5 and angle >= -5:\n",
    "                angle = 0\n",
    "            elif angle <= 20 and angle >= 10:\n",
    "                angle = 1\n",
    "            elif angle <= 35 and angle >= 25:\n",
    "                angle = 2\n",
    "            elif angle <= 50 and angle >= 40:\n",
    "                angle = 3\n",
    "            elif angle <= 65 and angle >= 55:\n",
    "                angle = 4\n",
    "            elif angle <= 80 and angle >= 70:\n",
    "                angle = 5\n",
    "        \n",
    "        match = re.search(r'^(\\d+)', img)\n",
    "        if match:\n",
    "            label = int(match.group(1)) - 1\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ada76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_0_dataset = FacePix_Dataset(\"D:\\\\jupyter_notebooks\\\\Experiments\\\\FacePix\\dataset\\\\default_angle\", transform=transform)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "angle_0_train_dataset, angle_0_valid_dataset = torch.utils.data.random_split(angle_0_dataset, [int(len(angle_0_dataset)*0.8), int(len(angle_0_dataset)*0.2)],generator=generator)\n",
    "train_loader = torch.utils.data.DataLoader(angle_0_train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.train()\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader)\n",
    "    loss_epoch=0\n",
    "    i=1\n",
    "    for images, labels, angles in loop:\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        angles = angles.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        i +=1\n",
    "      \n",
    "    loss_epoch /= i\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_epoch:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"D:\\\\jupyter_notebooks\\\\Experiments\\\\FacePix\\\\models\", f\"facepix_model_{model_name}\"+\".pth\")\n",
    "#torch.save(model.state_dict(), model_path)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 30\n",
    "#evaluate on valid_dataset\n",
    "with torch.no_grad():\n",
    "    true_class = 0\n",
    "    false_positives = np.zeros(num_classes)\n",
    "    false_negatives = np.zeros(num_classes)\n",
    "    true_positives = np.zeros(num_classes)\n",
    "    model.eval()\n",
    "    for i in range(len(angle_0_valid_dataset)):\n",
    "        if int(i%100)==0:\n",
    "            print(i)\n",
    "        valid_img = torch.unsqueeze(angle_0_valid_dataset[i][0],0)\n",
    "        valid_img = valid_img.to(device)\n",
    "        pred = model(valid_img)\n",
    "        pred_class = pred.argmax().item()\n",
    "        \n",
    "        # Update true positives, false positives, and false negatives for each class\n",
    "        true_label = angle_0_valid_dataset[i][1]\n",
    "        if pred_class == true_label:\n",
    "            true_positives[true_label] += 1\n",
    "        else:\n",
    "            false_negatives[true_label] += 1\n",
    "            false_positives[pred_class] += 1\n",
    "            \n",
    "    # Calculate precision and recall for each class\n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    for c in range(num_classes):\n",
    "        precision[c] = true_positives[c] / (true_positives[c] + false_positives[c]) if (true_positives[c] + false_positives[c]) > 0 else 0\n",
    "        recall[c] = true_positives[c] / (true_positives[c] + false_negatives[c]) if (true_positives[c] + false_negatives[c]) > 0 else 0\n",
    "\n",
    "    # Calculate macro precision, recall, and accuracy\n",
    "    macro_precision_default = np.mean(precision)\n",
    "    macro_recall_default = np.mean(recall)\n",
    "    macro_f1_score_default = 2*macro_precision_default*macro_recall_default/(macro_precision_default+macro_recall_default)\n",
    "    macro_accuracy_default = np.sum(true_positives) / len(angle_0_valid_dataset)\n",
    "\n",
    "    print(\"Accuracy: \", macro_accuracy_default)\n",
    "    print(\"Precision: \", macro_precision_default)\n",
    "    print(\"Recall: \", macro_recall_default)\n",
    "    print(\"F1 Score: \", macro_f1_score_default)\n",
    "    default_scores = [macro_accuracy_default,macro_precision_default,macro_recall_default,macro_f1_score_default]\n",
    "    default_scores = np.reshape(np.array(default_scores),(1,4))\n",
    "\n",
    "save_dir = 'default_scores'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "scores = ['Accuracy','Precision','Recall','F1 Score']\n",
    "default_scores_df = pd.DataFrame(data=default_scores,columns=scores)\n",
    "default_scores_df.to_csv(f'{save_dir}\\\\{model_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TTA_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd31c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTA_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, target_network, path):\n",
    "        self.dataset = dataset\n",
    "        self.target_network = target_network\n",
    "        self.path = path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        self.target_network.eval()\n",
    "\n",
    "        image, label, angle = self.dataset[idx]\n",
    "        image = torch.unsqueeze(image,0)\n",
    "        image = image.to(device)\n",
    "        \n",
    "        TTA_lst = []\n",
    "        TTA_lst_numpy = []\n",
    "        for img2 in os.listdir(self.path):\n",
    "            match = re.search(r'^(\\d+)', img2)\n",
    "            if match:\n",
    "                img2_label = int(match.group(1)) - 1\n",
    "                \n",
    "            match_2 = re.search(r'\\((-?\\d+)\\)', img2)\n",
    "            if match_2:\n",
    "                img2_angle = int(match_2.group(1))\n",
    "            \n",
    "            if label == img2_label and int((angle-img2_angle)%15)==0:\n",
    "                tta_img = cv2.imread(os.path.join(self.path,img2))\n",
    "                tta_img = transform(tta_img)\n",
    "                tta_img = torch.unsqueeze(tta_img,0)\n",
    "                TTA_lst_numpy.append(tta_img.numpy())\n",
    "                tta_img = tta_img.to(device)\n",
    "                TTA_lst.append(tta_img)\n",
    "        \n",
    "        tta_pred_lst = []\n",
    "        uncertainty_lst = []\n",
    "        loss_lst = []\n",
    "        label = torch.ones(1,dtype=int)*label\n",
    "        label = label.to(device)\n",
    "        for tta_img in TTA_lst:\n",
    "            tta_pred = self.target_network(tta_img)\n",
    "            tta_pred_lst.append(torch.squeeze(tta_pred,0).cpu().detach().numpy())\n",
    "            prediction, confidence, entropy, margin, NLL, Brier, ODIN_temp, MCD_temp, purview_initial_temp, purview_final_temp, grad_norm, grad_trust = get_uncertainties(tta_img,self.target_network)\n",
    "            \n",
    "            #uncertainties\n",
    "            inv_confidence = 1/confidence[0]\n",
    "            entropy = -entropy[0]\n",
    "            inv_margin = 1/margin[0]\n",
    "            NLL = NLL\n",
    "            Brier = Brier\n",
    "            ODIN_temp = ODIN_temp\n",
    "            MCD_temp = -MCD_temp[0]\n",
    "            purview_initial_temp = -purview_initial_temp\n",
    "            purview_final_temp = -purview_final_temp\n",
    "            grad_norm = -grad_norm\n",
    "            grad_trust = grad_trust\n",
    "            \n",
    "            uncertainty = [inv_confidence,entropy,inv_margin,NLL,Brier,ODIN_temp,MCD_temp,purview_initial_temp,purview_final_temp,grad_norm,grad_trust]\n",
    "            uncertainty_lst.append(uncertainty)\n",
    "        tta_uncertainty = np.array(uncertainty_lst)\n",
    "        \n",
    "        #original\n",
    "        pred = self.target_network(image)\n",
    "        orig_prediction, orig_confidence, orig_entropy, orig_margin, orig_NLL, orig_Brier, orig_ODIN_temp, orig_MCD_temp, orig_purview_initial_temp, orig_purview_final_temp, orig_grad_norm, orig_grad_trust = get_uncertainties(image,self.target_network)\n",
    "        \n",
    "        #uncertainties\n",
    "        orig_inv_confidence = 1/orig_confidence[0]\n",
    "        orig_entropy = -orig_entropy[0]\n",
    "        orig_inv_margin = 1/orig_margin[0]\n",
    "        orig_NLL = orig_NLL\n",
    "        orig_Brier = orig_Brier\n",
    "        orig_ODIN_temp = orig_ODIN_temp\n",
    "        orig_MCD_temp = -orig_MCD_temp[0]\n",
    "        orig_purview_initial_temp = -orig_purview_initial_temp\n",
    "        orig_purview_final_temp = -orig_purview_final_temp\n",
    "        orig_grad_norm = -orig_grad_norm\n",
    "        orig_grad_trust = orig_grad_trust\n",
    "        \n",
    "        orig_uncertainty = [orig_inv_confidence,orig_entropy,orig_inv_margin,orig_NLL,orig_Brier,orig_ODIN_temp,orig_MCD_temp,orig_purview_initial_temp,orig_purview_final_temp,orig_grad_norm,orig_grad_trust]\n",
    "        orig_uncertainty = np.array(orig_uncertainty)\n",
    "        \n",
    "        image = torch.squeeze(image,0)\n",
    "        image = image.cpu().detach().numpy()\n",
    "        label = label.cpu().detach().numpy()[0]\n",
    "        pred = pred.cpu().detach().numpy()[0]\n",
    "        tta_pred_numpy = np.array(tta_pred_lst)\n",
    "        \n",
    "        return image, tta_uncertainty, label, TTA_lst_numpy, angle, orig_uncertainty, tta_pred_numpy, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_dataset = TTA_Dataset(angle_0_train_dataset, model, \"D:\\\\jupyter_notebooks\\\\Experiments\\\\FacePix\\\\dataset\\\\other_angles\")\n",
    "loss_predicter_loader = torch.utils.data.DataLoader(tta_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dacb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the best angle for every class-angle combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_angle_arr = np.zeros((11,30,5))\n",
    "for image, tta_uncertainty, label, TTA_lst_numpy, angle, orig_uncertainty, tta_pred_numpy, pred in tqdm(tta_dataset,ncols=100):\n",
    "    best_angle = np.argmin(tta_uncertainty,axis=0)\n",
    "    for i in range(class_angle_arr.shape[0]):\n",
    "        class_angle_arr[i,label,best_angle[i]] += 1\n",
    "\n",
    "np.save(f\"class_angle\\\\{model_name}\\\\class_angle_facepix.npy\",class_angle_arr)\n",
    "class_angle_arr = np.load(f\"class_angle\\\\{model_name}\\\\class_angle_facepix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f68ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_angle_arr = np.load(f\"class_angle\\\\{model_name}\\\\class_angle_facepix.npy\")\n",
    "class_angle_best_lst = []\n",
    "for i in range(class_angle_arr.shape[0]):\n",
    "    class_angle = class_angle_arr[i,:,:]\n",
    "    class_angle_best = np.argsort(class_angle, axis=1)[:,-1]\n",
    "    class_angle_second_best = np.argsort(class_angle, axis=1)[:,-2]\n",
    "    class_angle_best_second_best = np.array([class_angle_best,class_angle_second_best])\n",
    "    class_angle_best_lst.append(class_angle_best_second_best)\n",
    "class_angle_best_arr = np.array(class_angle_best_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65008c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_dataset_valid = TTA_Dataset(angle_0_valid_dataset, model, \"D:\\\\jupyter_notebooks\\\\Experiments\\\\FacePix\\\\dataset\\\\other_angles\")\n",
    "pred_lst = []\n",
    "tta_pred_lst = []\n",
    "orig_uncertainty_lst = []\n",
    "tta_uncertainty_lst = []\n",
    "for image, tta_uncertainty, label, TTA_lst_numpy, angle, orig_uncertainty, tta_pred_numpy, pred in tqdm(tta_dataset_valid,ncols=100):\n",
    "    pred_lst.append(pred)\n",
    "    tta_pred_lst.append(tta_pred_numpy)\n",
    "    orig_uncertainty_lst.append(orig_uncertainty)\n",
    "    tta_uncertainty_lst.append(tta_uncertainty)\n",
    "\n",
    "np.save(f\"numpy_arrays\\\\{model_name}\\\\pred.npy\",np.array(pred_lst))\n",
    "np.save(f\"numpy_arrays\\\\{model_name}\\\\tta_pred.npy\",np.array(tta_pred_lst))\n",
    "np.save(f\"numpy_arrays\\\\{model_name}\\\\orig_uncertainty.npy\",np.array(orig_uncertainty_lst))\n",
    "np.save(f\"numpy_arrays\\\\{model_name}\\\\tta_uncertainty.npy\",np.array(tta_uncertainty_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ccd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array = np.load(f\"numpy_arrays\\\\{model_name}\\\\pred.npy\")\n",
    "tta_pred_array = np.load(f\"numpy_arrays\\\\{model_name}\\\\tta_pred.npy\")\n",
    "orig_uncertainty_array = np.load(f\"numpy_arrays\\\\{model_name}\\\\orig_uncertainty.npy\")\n",
    "tta_uncertainty_array = np.load(f\"numpy_arrays\\\\{model_name}\\\\tta_uncertainty.npy\")\n",
    "max_uncertainty = np.nanmax(orig_uncertainty_array,axis=0)\n",
    "min_uncertainty = np.nanmin(orig_uncertainty_array,axis=0)\n",
    "print(pred_array.shape)\n",
    "print(tta_pred_array.shape)\n",
    "print(orig_uncertainty_array.shape)\n",
    "print(tta_uncertainty_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_uncertainty_mean = np.nanmean(orig_uncertainty_array,axis=0)\n",
    "tta_uncertainty_mean = np.nanmean(tta_uncertainty_array,axis=0)\n",
    "uncertainty_mean = np.concatenate((np.reshape(orig_uncertainty_mean,(1,11)),tta_uncertainty_mean),axis=0)\n",
    "uncertainties = ['inv_confidence','entropy','inv_margin','NLL','Brier','ODIN_temp','MCD_temp','purview_initial_temp','purview_final_temp','grad_norm','grad_trust']\n",
    "angle_names = ['Default Angle', 'Augmentation Angle 1', 'Augmentation Angle 2', 'Augmentation Angle 3', 'Augmentation Angle 4', 'Augmentation Angle 5']\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "uncertainty_df = pd.DataFrame(data=uncertainty_mean,columns=uncertainties,index=angle_names)\n",
    "uncertainty_df.to_csv(f'numpy_arrays\\\\{model_name}\\\\uncertainty_mean_table.csv')\n",
    "uncertainty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f'parameter_sweep_results\\\\{model_name}\\\\parameter_sweep_results_method_2'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "uncertainties = ['inv_confidence','entropy','inv_margin','NLL','Brier','ODIN_temp','MCD_temp','purview_initial_temp','purview_final_temp','grad_norm','grad_trust']\n",
    "tta_algorithms = ['Random Angle', 'Best Angle', 'Default + Best Angle', 'Default + 2 Best Angles']\n",
    "for u,uncertainty in enumerate(uncertainties):\n",
    "    for alg,tta_algorithm in enumerate(tta_algorithms):\n",
    "        algorithm = tta_algorithm + ' ' + uncertainty\n",
    "        threshold_bins = np.linspace(min_uncertainty[u], max_uncertainty[u], 11)\n",
    "        class_accuracy_lst = []\n",
    "        class_precision_lst = []\n",
    "        class_recall_lst = []\n",
    "        class_f1_score_lst = []\n",
    "\n",
    "        num_classes = pred_array.shape[1]\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for j, uncertainty_threshold in enumerate(threshold_bins):\n",
    "                if j==10:\n",
    "                    print(j)\n",
    "                true_class = 0\n",
    "                false_positives = np.zeros(num_classes)\n",
    "                false_negatives = np.zeros(num_classes)\n",
    "                true_positives = np.zeros(num_classes)\n",
    "\n",
    "                for i in range(len(angle_0_valid_dataset)):\n",
    "                    orig_uncertainty = orig_uncertainty_array[i,u] \n",
    "                    first_pred = pred_array[i,:]\n",
    "                    first_pred_class = first_pred.argmax().item()\n",
    "\n",
    "                    if orig_uncertainty < uncertainty_threshold:\n",
    "                        pred_class = first_pred_class\n",
    "                    else:\n",
    "                        if alg==0:\n",
    "                            best_idx = np.random.randint(0,5)\n",
    "                            pred = tta_pred_array[i,best_idx,:]\n",
    "                        elif alg==1:\n",
    "                            best_idx = class_angle_best_arr[u,0,first_pred_class]\n",
    "                            pred = tta_pred_array[i,best_idx,:]\n",
    "                        elif alg==2:\n",
    "                            best_idx = class_angle_best_arr[u,0,first_pred_class]\n",
    "                            pred_aug = tta_pred_array[i,best_idx,:]\n",
    "                            pred = (first_pred + pred_aug)/2\n",
    "                        elif alg==3:\n",
    "                            best_idx = class_angle_best_arr[u,0,first_pred_class]\n",
    "                            second_best_idx = class_angle_best_arr[u,1,first_pred_class]\n",
    "                            pred_aug = tta_pred_array[i,best_idx,:]\n",
    "                            second_pred_aug = tta_pred_array[i,second_best_idx,:]\n",
    "                            pred = (first_pred + pred_aug + second_pred_aug)/3\n",
    "      \n",
    "                        pred_class = pred.argmax().item()\n",
    "\n",
    "                    # Update true positives, false positives, and false negatives for each class\n",
    "                    true_label = angle_0_valid_dataset[i][1]\n",
    "                    if pred_class == true_label:\n",
    "                        true_positives[true_label] += 1\n",
    "                    else:\n",
    "                        false_negatives[true_label] += 1\n",
    "                        false_positives[pred_class] += 1\n",
    "\n",
    "                # Calculate precision and recall for each class\n",
    "                precision = np.zeros(num_classes)\n",
    "                recall = np.zeros(num_classes)\n",
    "                for c in range(num_classes):\n",
    "                    precision[c] = true_positives[c] / (true_positives[c] + false_positives[c]) if (true_positives[c] + false_positives[c]) > 0 else 0\n",
    "                    recall[c] = true_positives[c] / (true_positives[c] + false_negatives[c]) if (true_positives[c] + false_negatives[c]) > 0 else 0\n",
    "\n",
    "                # Calculate macro precision, recall, and accuracy\n",
    "                macro_precision = np.mean(precision)\n",
    "                macro_recall = np.mean(recall)\n",
    "                macro_f1_score = 2*macro_precision*macro_recall/(macro_precision+macro_recall)\n",
    "                macro_accuracy = np.sum(true_positives) / len(angle_0_valid_dataset)\n",
    "\n",
    "                class_accuracy_lst.append(macro_accuracy)\n",
    "                class_precision_lst.append(macro_precision)\n",
    "                class_recall_lst.append(macro_recall)\n",
    "                class_f1_score_lst.append(macro_f1_score)\n",
    "\n",
    "        # Save or plot your results as needed\n",
    "        np.save(f\"{save_dir}\\\\{algorithm}_accuracies.npy\", np.array(class_accuracy_lst))\n",
    "        np.save(f\"{save_dir}\\\\{algorithm}_precisions.npy\", np.array(class_precision_lst))\n",
    "        np.save(f\"{save_dir}\\\\{algorithm}_recalls.npy\", np.array(class_recall_lst))\n",
    "        np.save(f\"{save_dir}\\\\{algorithm}_f1_score.npy\", np.array(class_f1_score_lst))\n",
    "\n",
    "#plot accuracy\n",
    "for u,uncertainty in enumerate(uncertainties):\n",
    "    plt.figure()\n",
    "    for alg,tta_algorithm in enumerate(tta_algorithms):\n",
    "        algorithm = tta_algorithm + ' ' + uncertainty\n",
    "        accuracy_array = np.load(f\"{save_dir}\\\\{algorithm}_accuracies.npy\")\n",
    "        plt.plot(np.linspace(1, 11, 11), accuracy_array, label=algorithm)\n",
    "    plt.plot(np.linspace(1, 11, 11), np.repeat(macro_accuracy_default,11), linestyle='dashed', label='Test Accuracy')\n",
    "    plt.xlabel('Uncertainty Threshold')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.title(f'Test Accuracy vs Uncertainty Threshold ({uncertainty})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_dir}\\\\Test Accuracy vs Uncertainty Threshold ({uncertainty}).jpg')\n",
    "\n",
    "#plot precision\n",
    "for u,uncertainty in enumerate(uncertainties):\n",
    "    plt.figure()\n",
    "    for alg,tta_algorithm in enumerate(tta_algorithms):\n",
    "        algorithm = tta_algorithm + ' ' + uncertainty\n",
    "        precision_array = np.load(f\"{save_dir}\\\\{algorithm}_precisions.npy\")\n",
    "        plt.plot(np.linspace(1, 11, 11), precision_array, label=algorithm)\n",
    "    plt.plot(np.linspace(1, 11, 11), np.repeat(macro_precision_default,11), linestyle='dashed', label='Test Precision')\n",
    "    plt.xlabel('Uncertainty Threshold')\n",
    "    plt.ylabel('Test Precision')\n",
    "    plt.title(f'Test Precision vs Uncertainty Threshold ({uncertainty})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_dir}\\\\Test Precision vs Uncertainty Threshold ({uncertainty}).jpg')\n",
    "\n",
    "#plot recall\n",
    "for u,uncertainty in enumerate(uncertainties):\n",
    "    plt.figure()\n",
    "    for alg,tta_algorithm in enumerate(tta_algorithms):\n",
    "        algorithm = tta_algorithm + ' ' + uncertainty\n",
    "        recall_array = np.load(f\"{save_dir}\\\\{algorithm}_recalls.npy\")\n",
    "        plt.plot(np.linspace(1, 11, 11), recall_array, label=algorithm)\n",
    "    plt.plot(np.linspace(1, 11, 11), np.repeat(macro_recall_default,11), linestyle='dashed', label='Test Recall')\n",
    "    plt.xlabel('Uncertainty Threshold')\n",
    "    plt.ylabel('Test Recall')\n",
    "    plt.title(f'Test Recall vs Uncertainty Threshold ({uncertainty})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_dir}\\\\Test Recall vs Uncertainty Threshold ({uncertainty}).jpg')\n",
    "\n",
    "#plot f1-score\n",
    "for u,uncertainty in enumerate(uncertainties):\n",
    "    plt.figure()\n",
    "    for alg,tta_algorithm in enumerate(tta_algorithms):\n",
    "        algorithm = tta_algorithm + ' ' + uncertainty\n",
    "        f1_score_array = np.load(f\"{save_dir}\\\\{algorithm}_f1_score.npy\")\n",
    "        plt.plot(np.linspace(1, 11, 11), f1_score_array, label=algorithm)\n",
    "    plt.plot(np.linspace(1, 11, 11), np.repeat(macro_f1_score_default,11), linestyle='dashed', label='Test F1-Score')\n",
    "    plt.xlabel('Uncertainty Threshold')\n",
    "    plt.ylabel('Test F1-Score')\n",
    "    plt.title(f'Test F1-Score vs Uncertainty Threshold ({uncertainty})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{save_dir}\\\\Test F1-Score vs Uncertainty Threshold ({uncertainty}).jpg')\n",
    "    \n",
    "#calculate normalized auc\n",
    "with open(f'{save_dir}\\\\auc_results.txt', 'w') as file:\n",
    "    for u, uncertainty in enumerate(uncertainties):\n",
    "        best_auc = 0\n",
    "        best_tta_algorithm = None\n",
    "        file.write(uncertainty + '\\n')\n",
    "        for alg, tta_algorithm in enumerate(tta_algorithms):\n",
    "            algorithm = tta_algorithm + ' ' + uncertainty\n",
    "            accuracy_array = np.load(f\"{save_dir}\\\\{algorithm}_accuracies.npy\")\n",
    "            auc_value = auc(np.linspace(min_uncertainty[u], max_uncertainty[u], 11), accuracy_array)\n",
    "            normalized_auc = auc_value/(max_uncertainty[u]-min_uncertainty[u])\n",
    "            if normalized_auc > best_auc:\n",
    "                best_auc = normalized_auc\n",
    "                best_tta_algorithm = tta_algorithm\n",
    "            file.write(tta_algorithm + ': ' + str(normalized_auc) + '\\n')\n",
    "        file.write('Best Algorithm: '+ best_tta_algorithm + '\\n')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f261031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating auc table, finding max accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate normalized auc\n",
    "save_dir = f'parameter_sweep_results\\\\{model_name}\\\\parameter_sweep_results'\n",
    "uncertainties = ['inv_confidence','entropy','inv_margin','NLL','Brier','ODIN_temp','MCD_temp','purview_initial_temp','purview_final_temp','grad_norm','grad_trust']\n",
    "tta_algorithms = ['Random Angle', 'Best Angle', 'Default + Best Angle', 'Default + 2 Best Angles']\n",
    "auc_df = pd.DataFrame(data=np.zeros((4,11)),columns=uncertainties,index=tta_algorithms)\n",
    "max_acc_df = pd.DataFrame(data=np.zeros((4,11)),columns=uncertainties,index=tta_algorithms)\n",
    "arg_max_acc_df = pd.DataFrame(data=np.zeros((4,11)),columns=uncertainties,index=tta_algorithms)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "with open(f'{save_dir}\\\\auc_results.txt', 'w') as file:\n",
    "    for u, uncertainty in enumerate(uncertainties):\n",
    "        best_auc = 0\n",
    "        best_tta_algorithm = None\n",
    "        file.write(uncertainty + '\\n')\n",
    "        for alg, tta_algorithm in enumerate(tta_algorithms):\n",
    "            algorithm = tta_algorithm + ' ' + uncertainty\n",
    "            accuracy_array = np.load(f\"{save_dir}\\\\{algorithm}_accuracies.npy\")\n",
    "            max_acc_df.iloc[alg,u] = np.max(accuracy_array)\n",
    "            arg_max_acc_df.iloc[alg,u] = np.argmax(accuracy_array)\n",
    "            auc_value = auc(np.linspace(min_uncertainty[u], max_uncertainty[u], 11), accuracy_array)\n",
    "            normalized_auc = auc_value/(max_uncertainty[u]-min_uncertainty[u])\n",
    "            auc_df.iloc[alg,u] = normalized_auc\n",
    "            if normalized_auc > best_auc:\n",
    "                best_auc = normalized_auc\n",
    "                best_tta_algorithm = tta_algorithm\n",
    "            file.write(tta_algorithm + ': ' + str(normalized_auc) + '\\n')\n",
    "        file.write('Best Algorithm: '+ best_tta_algorithm + '\\n')\n",
    "        file.write('\\n')\n",
    "auc_df.to_csv(f'{save_dir}\\\\auc_table.csv')\n",
    "max_acc_df.to_csv(f'{save_dir}\\\\max_acc_table.csv')\n",
    "arg_max_acc_df.to_csv(f'{save_dir}\\\\arg_max_acc_table.csv')\n",
    "\n",
    "highlight_threshold = macro_accuracy_default  # You can adjust this threshold as needed\n",
    "\n",
    "# Function to make the element bold if it is higher than the threshold\n",
    "def highlight_max_with_threshold(s, threshold):\n",
    "    is_higher_than_threshold = s > threshold\n",
    "    return ['font-weight: bold' if v else '' for v in is_higher_than_threshold]\n",
    "\n",
    "# Apply the styling to the DataFrame with the specified threshold\n",
    "bold_auc_df = auc_df.style.apply(highlight_max_with_threshold, threshold=highlight_threshold).format('{:.2f}')\n",
    "bold_max_acc_df = max_acc_df.style.apply(highlight_max_with_threshold, threshold=highlight_threshold).format('{:.2f}')\n",
    "bold_max_acc_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
